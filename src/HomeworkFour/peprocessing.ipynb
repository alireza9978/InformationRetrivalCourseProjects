{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2vqqFEm_Lfk"
      },
      "source": [
        "### import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RYaov3FT9CCz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "import json\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo9V-gs4_Olh"
      },
      "source": [
        "### load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVQGXiRm9M1Z",
        "outputId": "c56f2d1f-73a8-42b2-db66-9e875d5ebee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1100 entries, 0 to 1099\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   course_name               1100 non-null   object\n",
            " 1   course_instructor_site    1090 non-null   object\n",
            " 2   course_site               1054 non-null   object\n",
            " 3   course_instructor         1070 non-null   object\n",
            " 4   course_cost               897 non-null    object\n",
            " 5   course_credential         819 non-null    object\n",
            " 6   course_level              725 non-null    object\n",
            " 7   course_duration           1041 non-null   object\n",
            " 8   course_language           1054 non-null   object\n",
            " 9   course_caption_languages  716 non-null    object\n",
            " 10  overview                  1060 non-null   object\n",
            " 11  syllabus                  848 non-null    object\n",
            " 12  subject                   1100 non-null   object\n",
            "dtypes: object(13)\n",
            "memory usage: 120.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../HomeworkThree/dataset.csv', index_col=0)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### detect free courses and extract numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsJZOG547bvS",
        "outputId": "28c093f0-407d-490a-ac3e-09a3fbd0a9f7"
      },
      "outputs": [],
      "source": [
        "def process_cost(cost):\n",
        "    cost = str(cost)\n",
        "    \n",
        "    if cost[0] == '$':\n",
        "        cost = int(cost.split('.')[0][1:])\n",
        "    elif 'Free' in cost or 'free' in cost:\n",
        "        cost = 0\n",
        "    else:\n",
        "        cost = None\n",
        "\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['course_credential'] = df['course_credential'].apply(process_cost)\n",
        "df['course_credential'].fillna((df['course_credential'].mean()), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### turn subtitle string into list of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def str2list(text):\n",
        "    text = str(text)\n",
        "    if text == 'nan' or text == '':\n",
        "        return []\n",
        "    text = text.split(', ')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['course_caption_languages'] = df['course_caption_languages'].apply(str2list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1100 entries, 0 to 1099\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   course_name               1100 non-null   object \n",
            " 1   course_instructor_site    1090 non-null   object \n",
            " 2   course_site               1054 non-null   object \n",
            " 3   course_instructor         1070 non-null   object \n",
            " 4   course_cost               897 non-null    object \n",
            " 5   course_credential         1100 non-null   float64\n",
            " 6   course_level              725 non-null    object \n",
            " 7   course_duration           1041 non-null   object \n",
            " 8   course_language           1054 non-null   object \n",
            " 9   course_caption_languages  1100 non-null   object \n",
            " 10  overview                  1060 non-null   object \n",
            " 11  syllabus                  848 non-null    object \n",
            " 12  subject                   1100 non-null   object \n",
            "dtypes: float64(1), object(12)\n",
            "memory usage: 120.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9UpxE9SFJBD"
      },
      "source": [
        "### clean texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8tnjWwJ-aYA"
      },
      "outputs": [],
      "source": [
        "def remove_special_characters(text):\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern,'',text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuaq4ZMx-hCO"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "  return text.lower().split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taJ_vutw-jKe",
        "outputId": "5ea2517e-081c-425b-d8c6-36acae9cf5e8"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "stopword = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(tokenized_overview):\n",
        "  cleaned_list = []\n",
        "  for word in tokenized_overview:\n",
        "    if word not in stopword:\n",
        "      cleaned_list.append(word)\n",
        "  return cleaned_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiBQYtxp-oND"
      },
      "outputs": [],
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "def stemmer(tokenized_overview):\n",
        "  stemmed_list = []\n",
        "  for word in tokenized_overview:\n",
        "    stemmed_list.append(ps.stem(word))\n",
        "  return stemmed_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kylDNIMw-sRw",
        "outputId": "0219dfcb-6a5f-4f99-81be-48471749a1b6"
      },
      "outputs": [],
      "source": [
        "nltk.download('wordnet')\n",
        "wn = WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer(tokenized_overview):\n",
        "  lemmatized_list = []\n",
        "  for word in tokenized_overview:\n",
        "    lemmatized_list.append(wn.lemmatize(word))\n",
        "  return lemmatized_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af3VA3dO-uqi"
      },
      "outputs": [],
      "source": [
        "def l2s(tokenize_text):\n",
        "  text = \" \" \n",
        "  return (text.join(tokenize_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "ipLeEQpK_E5k",
        "outputId": "a5f5404d-ffcd-44a8-90b3-c84f4850ac67"
      },
      "outputs": [],
      "source": [
        "df['x'] = df['x'].apply(remove_special_characters)\n",
        "df['tokenized_x'] = df['x'].apply(tokenize_text)\n",
        "df['tokenized_x'] = df['tokenized_x'].apply(remove_stopwords)\n",
        "df['tokenized_x'] = df['tokenized_x'].apply(stemmer)\n",
        "df['tokenized_x'] = df['tokenized_x'].apply(lemmatizer)\n",
        "df['cleaned_x'] = df['tokenized_x'].apply(l2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "almas_preprocess.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
